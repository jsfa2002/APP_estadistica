# -*- coding: utf-8 -*-
"""app3

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/19ypVmeuLg4oZ8maZp-MtDLDaJmcBfGHv
"""
import streamlit as st
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression, LogisticRegression
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis
from sklearn.metrics import confusion_matrix, accuracy_score, classification_report, mean_squared_error, r2_score
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler
from sklearn.impute import SimpleImputer
from prince import MCA

# Configuraci贸n de la p谩gina
st.set_page_config(page_title="ReDim - An谩lisis Multivariado", layout="wide")
st.title(' ReDim: An谩lisis Multivariado Completo')

# CSS personalizado
st.markdown("""
    <style>
    .stApp { background-color: #f5f5f5; }
    h1 { color: #4CAF50; text-align: center; }
    .sidebar .sidebar-content { background-color: #f0f2f6; }
    </style>
    """, unsafe_allow_html=True)

# Sidebar para subir el archivo
st.sidebar.header("Opciones de Datos")
uploaded_file = st.sidebar.file_uploader("Sube tu archivo CSV", type=["csv"])

if uploaded_file is not None:
    df = pd.read_csv(uploaded_file)
    st.sidebar.success("Archivo cargado exitosamente!")
    
    # Identificar tipos de columnas
    numeric_cols = df.select_dtypes(include=['float64', 'int64']).columns
    cat_cols = df.select_dtypes(include=['object', 'category']).columns
    
    # Mostrar vista previa de datos
    st.subheader(" Vista previa de los datos")
    st.dataframe(df.head())
    
    # Mostrar informaci贸n b谩sica del dataset
    st.subheader(" Informaci贸n del Dataset")
    col1, col2 = st.columns(2)
    with col1:
        st.write("**Variables Num茅ricas:**", list(numeric_cols))
    with col2:
        st.write("**Variables Categ贸ricas:**", list(cat_cols))
    
    # Men煤 de an谩lisis
    analysis_type = st.sidebar.radio("Selecciona el tipo de an谩lisis", 
                                   ["EDA", "Modelos Predictivos", "PCA", "MCA"])
    
    # ====================== EDA ======================
    if analysis_type == "EDA":
        st.subheader(" An谩lisis Exploratorio de Datos (EDA)")
        
        # Estad铆sticas descriptivas
        st.write("### Estad铆sticas descriptivas")
        st.write(df.describe())
        
        # Valores nulos
        st.write("### Valores nulos por columna")
        null_data = df.isnull().sum().reset_index()
        null_data.columns = ['Variable', 'Conteo Nulos']
        st.bar_chart(null_data.set_index('Variable'))
        
        # Distribuci贸n de variables num茅ricas
        if len(numeric_cols) > 0:
            st.write("### Distribuci贸n de variables num茅ricas")
            selected_num = st.selectbox("Selecciona variable num茅rica", numeric_cols)
            fig, ax = plt.subplots(1, 2, figsize=(12, 4))
            sns.histplot(df[selected_num], kde=True, ax=ax[0])
            sns.boxplot(x=df[selected_num], ax=ax[1])
            st.pyplot(fig)
        
        # Conteo de categor铆as
        if len(cat_cols) > 0:
            st.write("### Conteo de categor铆as")
            selected_cat = st.selectbox("Selecciona variable categ贸rica", cat_cols)
            fig, ax = plt.subplots(figsize=(8, 4))
            sns.countplot(y=selected_cat, data=df, ax=ax, order=df[selected_cat].value_counts().index)
            st.pyplot(fig)
        
        # Correlaci贸n num茅rica
        if len(numeric_cols) > 1:
            st.write("### Matriz de correlaci贸n")
            corr_matrix = df[numeric_cols].corr()
            fig, ax = plt.subplots(figsize=(10, 8))
            sns.heatmap(corr_matrix, annot=True, fmt=".2f", cmap='coolwarm', ax=ax)
            st.pyplot(fig)
    
    # ====================== MODELOS PREDICTIVOS ======================
    elif analysis_type == "Modelos Predictivos":
        st.subheader(" Modelos Predictivos")
        
        model_choice = st.selectbox("Selecciona el modelo", 
                                  ["Regresi贸n Lineal", "Regresi贸n Log铆stica", "LDA", "QDA"])
        
        target_var = st.selectbox("Selecciona la variable dependiente (Y)", df.columns)
        predictor_vars = st.multiselect("Selecciona las variables predictoras (X)", 
                                       df.columns.drop(target_var))
        
        if st.button("Ejecutar Modelo"):
            st.subheader(f" Resultados del Modelo: {model_choice}")
            
            X = df[predictor_vars]
            y = df[target_var]
            
            # Manejo de variables categ贸ricas si es necesario
            if X.select_dtypes(include=['object']).any().any():
                X = pd.get_dummies(X, drop_first=True)
            
            # Partici贸n del dataset
            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)
            
            # Selecci贸n del modelo
            if model_choice == "Regresi贸n Lineal":
                model = LinearRegression()
                model_type = "regression"
            elif model_choice == "Regresi贸n Log铆stica":
                model = LogisticRegression(max_iter=1000)
                model_type = "classification"
            elif model_choice == "LDA":
                model = LinearDiscriminantAnalysis()
                model_type = "classification"
            else:
                model = QuadraticDiscriminantAnalysis()
                model_type = "classification"
            
            # Entrenamiento y predicci贸n
            model.fit(X_train, y_train)
            y_pred = model.predict(X_test)
            
            # Resultados
            if model_type == "regression":
                st.write("### M茅tricas de Regresi贸n")
                mse = mean_squared_error(y_test, y_pred)
                r2 = r2_score(y_test, y_pred)
                st.write(f"- Error Cuadr谩tico Medio (MSE): {mse:.4f}")
                st.write(f"- Coeficiente de Determinaci贸n (R虏): {r2:.4f}")
                
                # Gr谩fico de valores reales vs predichos
                fig, ax = plt.subplots()
                ax.scatter(y_test, y_pred, alpha=0.5)
                ax.plot([y.min(), y.max()], [y.min(), y.max()], 'k--', lw=2)
                ax.set_xlabel('Valores Reales')
                ax.set_ylabel('Valores Predichos')
                ax.set_title('Valores Reales vs Predichos')
                st.pyplot(fig)
            else:
                st.write("### Matriz de Confusi贸n")
                cm = confusion_matrix(y_test, y_pred)
                fig, ax = plt.subplots()
                sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax)
                ax.set_xlabel('Predicho')
                ax.set_ylabel('Real')
                st.pyplot(fig)
                
                st.write("### Reporte de Clasificaci贸n")
                st.text(classification_report(y_test, y_pred))
            
            st.success(f"{model_choice} ejecutado correctamente")
        
        # Comparaci贸n de modelos (solo para clasificaci贸n)
        if len(df[target_var].unique()) <= 5:  # Si parece variable categ贸rica
            if st.button("Comparar Modelos de Clasificaci贸n"):
                st.subheader(" Comparaci贸n de Modelos de Clasificaci贸n")
                
                X = df[predictor_vars]
                y = df[target_var]
                
                if X.select_dtypes(include=['object']).any().any():
                    X = pd.get_dummies(X, drop_first=True)
                
                X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)
                
                models = {
                    "Regresi贸n Log铆stica": LogisticRegression(max_iter=1000),
                    "LDA": LinearDiscriminantAnalysis(),
                    "QDA": QuadraticDiscriminantAnalysis()
                }
                
                results = []
                for name, model in models.items():
                    model.fit(X_train, y_train)
                    y_pred = model.predict(X_test)
                    acc = accuracy_score(y_test, y_pred)
                    results.append({"Modelo": name, "Exactitud": acc})
                
                results_df = pd.DataFrame(results)
                st.write(results_df)
                
                fig, ax = plt.subplots()
                sns.barplot(x='Exactitud', y='Modelo', data=results_df, ax=ax)
                ax.set_xlim(0, 1)
                st.pyplot(fig)
                
                best_model = results_df.loc[results_df['Exactitud'].idxmax()]
                st.success(f"El mejor modelo es {best_model['Modelo']} con una exactitud de {best_model['Exactitud']:.2f}")
    
    # ====================== PCA ======================
    elif analysis_type == "PCA":
        st.subheader(" An谩lisis de Componentes Principales (PCA)")
        
        if len(numeric_cols) < 2:
            st.error("Se necesitan al menos 2 variables num茅ricas para ejecutar PCA")
        else:
            # Selecci贸n de variables
            selected_vars = st.multiselect("Selecciona variables para PCA", 
                                         numeric_cols, default=list(numeric_cols))
            
            # Opciones de PCA
            n_components = st.slider("N煤mero de componentes", 2, min(10, len(selected_vars)), 2)
            
            if st.button("Ejecutar PCA"):
                # Preprocesamiento
                df_pca = df[selected_vars].copy()
                imputer = SimpleImputer(strategy='mean')
                df_filled = pd.DataFrame(imputer.fit_transform(df_pca), columns=selected_vars)
                
                scaler = StandardScaler()
                df_scaled = scaler.fit_transform(df_filled)
                
                # Aplicar PCA
                pca = PCA(n_components=n_components)
                pca.fit(df_scaled)
                components = pca.transform(df_scaled)
                
                # Resultados
                st.write("### Varianza explicada por cada componente")
                var_exp = pca.explained_variance_ratio_
                cum_var_exp = np.cumsum(var_exp)
                
                fig, ax = plt.subplots(1, 2, figsize=(15, 5))
                ax[0].bar(range(1, n_components+1), var_exp, alpha=0.6, align='center')
                ax[0].set_ylabel('Varianza explicada')
                ax[0].set_xlabel('Componente principal')
                ax[0].set_title('Varianza explicada por componente')
                
                ax[1].plot(range(1, n_components+1), cum_var_exp, 'o-')
                ax[1].set_ylabel('Varianza explicada acumulada')
                ax[1].set_xlabel('Componente principal')
                ax[1].set_title('Varianza acumulada')
                st.pyplot(fig)
                
                # Gr谩fico de componentes
                st.write("### Gr谩fico de los dos primeros componentes")
                fig, ax = plt.subplots(figsize=(8, 6))
                scatter = ax.scatter(components[:, 0], components[:, 1], alpha=0.6)
                ax.set_xlabel(f'PC1 ({var_exp[0]*100:.1f}%)')
                ax.set_ylabel(f'PC2 ({var_exp[1]*100:.1f}%)')
                ax.set_title('PCA: Componente 1 vs Componente 2')
                
                # Si hay una variable categ贸rica, usarla para colorear
                if len(cat_cols) > 0:
                    color_var = st.selectbox("Variable para colorear puntos", cat_cols)
                    unique_cats = df[color_var].unique()
                    colors = plt.cm.get_cmap('tab10', len(unique_cats))
                    
                    fig, ax = plt.subplots(figsize=(8, 6))
                    for i, cat in enumerate(unique_cats):
                        idx = df[color_var] == cat
                        ax.scatter(components[idx, 0], components[idx, 1], 
                                   color=colors(i), label=cat, alpha=0.6)
                    ax.legend(title=color_var)
                    ax.set_xlabel(f'PC1 ({var_exp[0]*100:.1f}%)')
                    ax.set_ylabel(f'PC2 ({var_exp[1]*100:.1f}%)')
                    ax.set_title('PCA coloreado por ' + color_var)
                
                st.pyplot(fig)
                
                # Cargas factoriales
                st.write("### Cargas factoriales (Componentes principales)")
                loadings = pd.DataFrame(
                    pca.components_.T,
                    columns=[f'PC{i+1}' for i in range(n_components)],
                    index=selected_vars
                )
                st.write(loadings)
                
                st.success("PCA ejecutado correctamente")
    
    # ====================== MCA ======================
    elif analysis_type == "MCA":
        st.subheader(" An谩lisis de Correspondencias M煤ltiples (MCA)")
        
        if len(cat_cols) < 2:
            st.warning("Se necesitan al menos dos columnas categ贸ricas para ejecutar MCA")
        else:
            # Selecci贸n de variables
            selected_cats = st.multiselect("Selecciona variables categ贸ricas para MCA", 
                                         cat_cols, default=list(cat_cols)[:min(5, len(cat_cols))])
            
            n_components = st.slider("N煤mero de dimensiones", 2, min(5, len(selected_cats)), 2)
            
            if st.button("Ejecutar MCA"):
                df_mca = df[selected_cats].copy().astype(str)
                
                # Aplicar MCA
                mca = MCA(n_components=n_components, n_iter=10, random_state=42)
                mca.fit(df_mca)
                
                # Coordenadas
                mca_coords = mca.row_coordinates(df_mca)
                mca_col_coords = mca.column_coordinates(df_mca)
                
                # Inercia
                eigenvalues = mca.eigenvalues_
                total_inertia = sum(eigenvalues)
                explained_inertia = [eig / total_inertia for eig in eigenvalues]
                
                # Resultados
                st.write("### Inercia explicada por cada dimensi贸n")
                fig, ax = plt.subplots(figsize=(8, 4))
                ax.bar(range(1, n_components+1), explained_inertia, alpha=0.6)
                ax.set_xlabel('Dimensi贸n')
                ax.set_ylabel('Proporci贸n de inercia explicada')
                st.pyplot(fig)
                
                # Gr谩fico de individuos
                st.write("### Gr谩fico de Individuos (dos primeras dimensiones)")
                fig, ax = plt.subplots(figsize=(8, 6))
                ax.scatter(mca_coords.iloc[:, 0], mca_coords.iloc[:, 1], alpha=0.5, color='blue')
                ax.axhline(0, color='gray', linestyle='--', alpha=0.5)
                ax.axvline(0, color='gray', linestyle='--', alpha=0.5)
                ax.set_xlabel(f"Dimensi贸n 1 ({explained_inertia[0]*100:.1f}%)")
                ax.set_ylabel(f"Dimensi贸n 2 ({explained_inertia[1]*100:.1f}%)")
                ax.set_title("MCA: Individuos")
                st.pyplot(fig)
                
                # Gr谩fico de categor铆as
                st.write("### Gr谩fico de Categor铆as (dos primeras dimensiones)")
                fig, ax = plt.subplots(figsize=(10, 8))
                
                colors = plt.cm.get_cmap('tab10', len(selected_cats))
                for i, var in enumerate(selected_cats):
                    idx = mca_col_coords.index.str.startswith(var)
                    ax.scatter(mca_col_coords.iloc[idx, 0], mca_col_coords.iloc[idx, 1], 
                              color=colors(i), label=var, alpha=0.7)
                
                ax.axhline(0, color='gray', linestyle='--', alpha=0.5)
                ax.axvline(0, color='gray', linestyle='--', alpha=0.5)
                ax.set_xlabel(f"Dimensi贸n 1 ({explained_inertia[0]*100:.1f}%)")
                ax.set_ylabel(f"Dimensi贸n 2 ({explained_inertia[1]*100:.1f}%)")
                ax.set_title("MCA: Categor铆as")
                ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
                st.pyplot(fig)
                
                st.success("MCA ejecutado correctamente")

st.sidebar.markdown("---")
st.sidebar.markdown(" Desarrollado con cari帽o por ReDim Team")

