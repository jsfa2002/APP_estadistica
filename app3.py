# -*- coding: utf-8 -*-
"""app3

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/19ypVmeuLg4oZ8maZp-MtDLDaJmcBfGHv
"""
import streamlit as st
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression, LogisticRegression
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis
from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor, plot_tree
from sklearn.metrics import confusion_matrix, accuracy_score, classification_report, mean_squared_error, r2_score, precision_score, recall_score, f1_score
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler
from sklearn.impute import SimpleImputer
from prince import MCA
from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor
from sklearn.model_selection import GridSearchCV

# Configuración de la página
st.set_page_config(page_title="ReDim - Análisis Multivariado", layout="wide")
st.title('📊 ReDim: Análisis Multivariado Completo')

# CSS personalizado
st.markdown("""
    <style>
    .stApp { background-color: #f5f5f5; }
    h1 { color: #4CAF50; text-align: center; }
    .sidebar .sidebar-content { background-color: #f0f2f6; }
    </style>
    """, unsafe_allow_html=True)

# Sidebar para subir el archivo
st.sidebar.header("Opciones de Datos")
uploaded_file = st.sidebar.file_uploader("Sube tu archivo CSV", type=["csv"])

if uploaded_file is not None:
    df = pd.read_csv(uploaded_file)
    st.sidebar.success("Archivo cargado exitosamente!")
    
    # Identificar tipos de columnas
    numeric_cols = df.select_dtypes(include=['float64', 'int64']).columns
    cat_cols = df.select_dtypes(include=['object', 'category']).columns
    
    # Mostrar vista previa de datos
    st.subheader("📌 Vista previa de los datos")
    st.dataframe(df.head())
    
    # Mostrar información básica del dataset
    st.subheader("🔍 Información del Dataset")
    col1, col2 = st.columns(2)
    with col1:
        st.write("**Variables Numéricas:**", list(numeric_cols))
    with col2:
        st.write("**Variables Categóricas:**", list(cat_cols))
    
    # Menú de análisis
    analysis_type = st.sidebar.radio("Selecciona el tipo de análisis", 
                                   ["EDA", "Modelos Predictivos", "PCA", "MCA"])
    
    # ====================== EDA ======================
    if analysis_type == "EDA":
        st.subheader("📊 Análisis Exploratorio de Datos (EDA)")
        
        # Estadísticas descriptivas
        st.write("### Estadísticas descriptivas")
        st.write(df.describe())
        
        # Valores nulos
        st.write("### Valores nulos por columna")
        null_data = df.isnull().sum().reset_index()
        null_data.columns = ['Variable', 'Conteo Nulos']
        st.bar_chart(null_data.set_index('Variable'))
        
        # Distribución de variables numéricas
        if len(numeric_cols) > 0:
            st.write("### Distribución de variables numéricas")
            selected_num = st.selectbox("Selecciona variable numérica", numeric_cols)
            fig, ax = plt.subplots(1, 2, figsize=(12, 4))
            sns.histplot(df[selected_num], kde=True, ax=ax[0])
            sns.boxplot(x=df[selected_num], ax=ax[1])
            st.pyplot(fig)
        
        # Conteo de categorías
        if len(cat_cols) > 0:
            st.write("### Conteo de categorías")
            selected_cat = st.selectbox("Selecciona variable categórica", cat_cols)
            fig, ax = plt.subplots(figsize=(8, 4))
            sns.countplot(y=selected_cat, data=df, ax=ax, order=df[selected_cat].value_counts().index)
            st.pyplot(fig)
        
        # Correlación numérica
        if len(numeric_cols) > 1:
            st.write("### Matriz de correlación")
            corr_matrix = df[numeric_cols].corr()
            fig, ax = plt.subplots(figsize=(10, 8))
            sns.heatmap(corr_matrix, annot=True, fmt=".2f", cmap='coolwarm', ax=ax)
            st.pyplot(fig)
    
    # ====================== MODELOS PREDICTIVOS ======================
    elif analysis_type == "Modelos Predictivos":
        st.subheader("🔮 Modelos Predictivos")
        
        model_choice = st.selectbox("Selecciona el modelo", 
                                  ["Regresión Lineal", "Regresión Logística", "LDA", "QDA", 
                                   "Árbol de Decisión (Clasificación)", "Árbol de Decisión (Regresión)",
                                   "Random Forest (Clasificación)", "Random Forest (Regresión)"])
        
        target_var = st.selectbox("Selecciona la variable dependiente (Y)", df.columns)
        predictor_vars = st.multiselect("Selecciona las variables predictoras (X)", 
                                       df.columns.drop(target_var))
        
        # Configuración avanzada de modelos
        with st.expander("⚙️ Configuración del Modelo"):
            test_size = st.slider("Tamaño del conjunto de prueba (%)", 10, 40, 30)
            random_state = st.number_input("Semilla aleatoria", value=42)
            
            if "Árbol" in model_choice or "Forest" in model_choice:
                max_depth = st.number_input("Profundidad máxima del árbol", min_value=1, max_value=20, value=3)
                min_samples_split = st.number_input("Mínimo de muestras para dividir", min_value=2, max_value=20, value=2)
                if "Forest" in model_choice:
                    n_estimators = st.number_input("Número de árboles", min_value=10, max_value=500, value=100)
        
        if st.button("🔧 Entrenar Modelo"):
            st.subheader(f"📈 Resultados del Modelo: {model_choice}")
            
            X = df[predictor_vars]
            y = df[target_var]
            
            # Manejo de variables categóricas si es necesario
            if X.select_dtypes(include=['object']).any().any():
                X = pd.get_dummies(X, drop_first=True)
            
            # Partición del dataset
            X_train, X_test, y_train, y_test = train_test_split(
                X, y, test_size=test_size/100, random_state=random_state)
            
            # Selección y configuración del modelo
            model = None
            model_type = ""
            
            if model_choice == "Regresión Lineal":
                model = LinearRegression()
                model_type = "regression"
            elif model_choice == "Regresión Logística":
                model = LogisticRegression(max_iter=1000, random_state=random_state)
                model_type = "classification"
            elif model_choice == "LDA":
                model = LinearDiscriminantAnalysis()
                model_type = "classification"
            elif model_choice == "QDA":
                model = QuadraticDiscriminantAnalysis()
                model_type = "classification"
            elif model_choice == "Árbol de Decisión (Clasificación)":
                model = DecisionTreeClassifier(
                    max_depth=max_depth, 
                    min_samples_split=min_samples_split,
                    random_state=random_state)
                model_type = "classification"
            elif model_choice == "Árbol de Decisión (Regresión)":
                model = DecisionTreeRegressor(
                    max_depth=max_depth,
                    min_samples_split=min_samples_split,
                    random_state=random_state)
                model_type = "regression"
            elif model_choice == "Random Forest (Clasificación)":
                model = RandomForestClassifier(
                    n_estimators=n_estimators,
                    max_depth=max_depth,
                    min_samples_split=min_samples_split,
                    random_state=random_state)
                model_type = "classification"
            elif model_choice == "Random Forest (Regresión)":
                model = RandomForestRegressor(
                    n_estimators=n_estimators,
                    max_depth=max_depth,
                    min_samples_split=min_samples_split,
                    random_state=random_state)
                model_type = "regression"
            
            # Entrenamiento y predicción
            model.fit(X_train, y_train)
            y_pred = model.predict(X_test)
            
            # Resultados para regresión
            if model_type == "regression":
                st.write("### Métricas de Regresión")
                mse = mean_squared_error(y_test, y_pred)
                rmse = np.sqrt(mse)
                r2 = r2_score(y_test, y_pred)
                
                metrics_df = pd.DataFrame({
                    "Métrica": ["Error Cuadrático Medio (MSE)", "Raíz del Error Cuadrático Medio (RMSE)", 
                               "Coeficiente de Determinación (R²)"],
                    "Valor": [mse, rmse, r2]
                })
                st.dataframe(metrics_df.style.format({"Valor": "{:.4f}"}))
                
                # Gráfico de valores reales vs predichos
                fig, ax = plt.subplots()
                ax.scatter(y_test, y_pred, alpha=0.5)
                ax.plot([y.min(), y.max()], [y.min(), y.max()], 'k--', lw=2)
                ax.set_xlabel('Valores Reales')
                ax.set_ylabel('Valores Predichos')
                ax.set_title('Valores Reales vs Predichos')
                st.pyplot(fig)
                
                # Mostrar coeficientes para modelos lineales
                if hasattr(model, 'coef_'):
                    st.write("### Coeficientes del Modelo")
                    coef_df = pd.DataFrame({
                        "Variable": X.columns,
                        "Coeficiente": model.coef_.flatten()
                    })
                    st.dataframe(coef_df)
            
            # Resultados para clasificación
            else:
                st.write("### Métricas de Clasificación")
                accuracy = accuracy_score(y_test, y_pred)
                precision = precision_score(y_test, y_pred, average='weighted')
                recall = recall_score(y_test, y_pred, average='weighted')
                f1 = f1_score(y_test, y_pred, average='weighted')
                
                metrics_df = pd.DataFrame({
                    "Métrica": ["Exactitud (Accuracy)", "Precisión (Precision)", 
                               "Sensibilidad (Recall)", "F1-Score"],
                    "Valor": [accuracy, precision, recall, f1]
                })
                st.dataframe(metrics_df.style.format({"Valor": "{:.4f}"}))
                
                st.write("### Matriz de Confusión")
                cm = confusion_matrix(y_test, y_pred)
                fig, ax = plt.subplots()
                sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax)
                ax.set_xlabel('Predicho')
                ax.set_ylabel('Real')
                st.pyplot(fig)
                
                st.write("### Reporte de Clasificación")
                st.text(classification_report(y_test, y_pred))
            
            # Visualización de árboles de decisión
            if "Árbol" in model_choice and not "Forest" in model_choice:
                st.write("### Visualización del Árbol de Decisión")
                fig, ax = plt.subplots(figsize=(20, 10))
                plot_tree(model, 
                          feature_names=X.columns, 
                          class_names=[str(c) for c in model.classes_] if model_type == "classification" else None,
                          filled=True, 
                          rounded=True,
                          ax=ax)
                st.pyplot(fig)
            
            st.success(f"Modelo {model_choice} entrenado y evaluado correctamente")
        
        # Comparación de modelos (solo para clasificación)
        if len(df[target_var].unique()) <= 5:  # Si parece variable categórica
            if st.button("🔍 Comparar Modelos de Clasificación"):
                st.subheader("📊 Comparación de Modelos de Clasificación")
                
                X = df[predictor_vars]
                y = df[target_var]
                
                if X.select_dtypes(include=['object']).any().any():
                    X = pd.get_dummies(X, drop_first=True)
                
                X_train, X_test, y_train, y_test = train_test_split(
                    X, y, test_size=test_size/100, random_state=random_state)
                
                models = {
                    "Regresión Logística": LogisticRegression(max_iter=1000, random_state=random_state),
                    "LDA": LinearDiscriminantAnalysis(),
                    "QDA": QuadraticDiscriminantAnalysis(),
                    "Árbol de Decisión": DecisionTreeClassifier(
                        max_depth=max_depth, 
                        min_samples_split=min_samples_split,
                        random_state=random_state),
                    "Random Forest": RandomForestClassifier(
                        n_estimators=n_estimators,
                        max_depth=max_depth,
                        min_samples_split=min_samples_split,
                        random_state=random_state)
                }
                
                results = []
                for name, model in models.items():
                    model.fit(X_train, y_train)
                    y_pred = model.predict(X_test)
                    acc = accuracy_score(y_test, y_pred)
                    prec = precision_score(y_test, y_pred, average='weighted')
                    rec = recall_score(y_test, y_pred, average='weighted')
                    f1 = f1_score(y_test, y_pred, average='weighted')
                    results.append({
                        "Modelo": name, 
                        "Exactitud": acc,
                        "Precisión": prec,
                        "Sensibilidad": rec,
                        "F1-Score": f1
                    })
                
                results_df = pd.DataFrame(results)
                st.write(results_df.style.format({
                    "Exactitud": "{:.4f}",
                    "Precisión": "{:.4f}",
                    "Sensibilidad": "{:.4f}",
                    "F1-Score": "{:.4f}"
                }))
                
                fig, ax = plt.subplots(figsize=(10, 6))
                results_df.set_index('Modelo').plot(kind='bar', ax=ax)
                ax.set_ylabel('Puntuación')
                ax.set_title('Comparación de Modelos de Clasificación')
                ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
                st.pyplot(fig)
                
                best_model = results_df.loc[results_df['Exactitud'].idxmax()]
                st.success(f"Modelo más exacto: {best_model['Modelo']} con {best_model['Exactitud']:.2%} de exactitud")
    
    # ====================== PCA ======================
    elif analysis_type == "PCA":
        st.subheader("🔎 Análisis de Componentes Principales (PCA)")
        
        if len(numeric_cols) < 2:
            st.error("Se necesitan al menos 2 variables numéricas para ejecutar PCA")
        else:
            # Selección de variables
            selected_vars = st.multiselect("Selecciona variables para PCA", 
                                         numeric_cols, default=list(numeric_cols))
            
            # Opciones de PCA
            n_components = st.slider("Número de componentes", 2, min(10, len(selected_vars)), 2)
            
            if st.button("Ejecutar PCA"):
                # Preprocesamiento
                df_pca = df[selected_vars].copy()
                imputer = SimpleImputer(strategy='mean')
                df_filled = pd.DataFrame(imputer.fit_transform(df_pca), columns=selected_vars)
                
                scaler = StandardScaler()
                df_scaled = scaler.fit_transform(df_filled)
                
                # Aplicar PCA
                pca = PCA(n_components=n_components)
                pca.fit(df_scaled)
                components = pca.transform(df_scaled)
                
                # Resultados
                st.write("### Varianza explicada por cada componente")
                var_exp = pca.explained_variance_ratio_
                cum_var_exp = np.cumsum(var_exp)
                
                fig, ax = plt.subplots(1, 2, figsize=(15, 5))
                ax[0].bar(range(1, n_components+1), var_exp, alpha=0.6, align='center')
                ax[0].set_ylabel('Varianza explicada')
                ax[0].set_xlabel('Componente principal')
                ax[0].set_title('Varianza explicada por componente')
                
                ax[1].plot(range(1, n_components+1), cum_var_exp, 'o-')
                ax[1].set_ylabel('Varianza explicada acumulada')
                ax[1].set_xlabel('Componente principal')
                ax[1].set_title('Varianza acumulada')
                st.pyplot(fig)
                
                # Gráfico de componentes
                st.write("### Gráfico de los dos primeros componentes")
                fig, ax = plt.subplots(figsize=(8, 6))
                scatter = ax.scatter(components[:, 0], components[:, 1], alpha=0.6)
                ax.set_xlabel(f'PC1 ({var_exp[0]*100:.1f}%)')
                ax.set_ylabel(f'PC2 ({var_exp[1]*100:.1f}%)')
                ax.set_title('PCA: Componente 1 vs Componente 2')
                
                # Si hay una variable categórica, usarla para colorear
                if len(cat_cols) > 0:
                    color_var = st.selectbox("Variable para colorear puntos", cat_cols)
                    unique_cats = df[color_var].unique()
                    colors = plt.cm.get_cmap('tab10', len(unique_cats))
                    
                    fig, ax = plt.subplots(figsize=(8, 6))
                    for i, cat in enumerate(unique_cats):
                        idx = df[color_var] == cat
                        ax.scatter(components[idx, 0], components[idx, 1], 
                                   color=colors(i), label=cat, alpha=0.6)
                    ax.legend(title=color_var)
                    ax.set_xlabel(f'PC1 ({var_exp[0]*100:.1f}%)')
                    ax.set_ylabel(f'PC2 ({var_exp[1]*100:.1f}%)')
                    ax.set_title('PCA coloreado por ' + color_var)
                
                st.pyplot(fig)
                
                # Cargas factoriales
                st.write("### Cargas factoriales (Componentes principales)")
                loadings = pd.DataFrame(
                    pca.components_.T,
                    columns=[f'PC{i+1}' for i in range(n_components)],
                    index=selected_vars
                )
                st.write(loadings)
                
                st.success("PCA ejecutado correctamente")
    
    # ====================== MCA ======================
    elif analysis_type == "MCA":
        st.subheader("🎭 Análisis de Correspondencias Múltiples (MCA)")
        
        if len(cat_cols) < 2:
            st.warning("Se necesitan al menos dos columnas categóricas para ejecutar MCA")
        else:
            # Selección de variables
            selected_cats = st.multiselect("Selecciona variables categóricas para MCA", 
                                         cat_cols, default=list(cat_cols)[:min(5, len(cat_cols))])
            
            n_components = st.slider("Número de dimensiones", 2, min(5, len(selected_cats)), 2)
            
            if st.button("Ejecutar MCA"):
                df_mca = df[selected_cats].copy().astype(str)
                
                # Aplicar MCA
                mca = MCA(n_components=n_components, n_iter=10, random_state=42)
                mca.fit(df_mca)
                
                # Coordenadas
                mca_coords = mca.row_coordinates(df_mca)
                mca_col_coords = mca.column_coordinates(df_mca)
                
                # Inercia
                eigenvalues = mca.eigenvalues_
                total_inertia = sum(eigenvalues)
                explained_inertia = [eig / total_inertia for eig in eigenvalues]
                
                # Resultados
                st.write("### Inercia explicada por cada dimensión")
                fig, ax = plt.subplots(figsize=(8, 4))
                ax.bar(range(1, n_components+1), explained_inertia, alpha=0.6)
                ax.set_xlabel('Dimensión')
                ax.set_ylabel('Proporción de inercia explicada')
                st.pyplot(fig)
                
                # Gráfico de individuos
                st.write("### Gráfico de Individuos (dos primeras dimensiones)")
                fig, ax = plt.subplots(figsize=(8, 6))
                ax.scatter(mca_coords.iloc[:, 0], mca_coords.iloc[:, 1], alpha=0.5, color='blue')
                ax.axhline(0, color='gray', linestyle='--', alpha=0.5)
                ax.axvline(0, color='gray', linestyle='--', alpha=0.5)
                ax.set_xlabel(f"Dimensión 1 ({explained_inertia[0]*100:.1f}%)")
                ax.set_ylabel(f"Dimensión 2 ({explained_inertia[1]*100:.1f}%)")
                ax.set_title("MCA: Individuos")
                st.pyplot(fig)
                
                # Gráfico de categorías
                st.write("### Gráfico de Categorías (dos primeras dimensiones)")
                fig, ax = plt.subplots(figsize=(10, 8))
                
                colors = plt.cm.get_cmap('tab10', len(selected_cats))
                for i, var in enumerate(selected_cats):
                    idx = mca_col_coords.index.str.startswith(var)
                    ax.scatter(mca_col_coords.iloc[idx, 0], mca_col_coords.iloc[idx, 1], 
                              color=colors(i), label=var, alpha=0.7)
                
                ax.axhline(0, color='gray', linestyle='--', alpha=0.5)
                ax.axvline(0, color='gray', linestyle='--', alpha=0.5)
                ax.set_xlabel(f"Dimensión 1 ({explained_inertia[0]*100:.1f}%)")
                ax.set_ylabel(f"Dimensión 2 ({explained_inertia[1]*100:.1f}%)")
                ax.set_title("MCA: Categorías")
                ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
                st.pyplot(fig)
                
                st.success("MCA ejecutado correctamente")

st.sidebar.markdown("---")
st.sidebar.markdown("🚀 Desarrollado con cariño por ReDim Team")
