# A√±ade al inicio del script (con los otros imports)
from collections import defaultdict

# Despu√©s de cargar el dataframe (en el if uploaded_file is not None)
if uploaded_file is not None:
    # Diccionario para almacenar resultados de modelos
    if 'model_results' not in st.session_state:
        st.session_state.model_results = defaultdict(dict)
    
    # [...] (todo el c√≥digo anterior se mantiene igual hasta la secci√≥n de Modelos Predictivos)

    # ====================== MODELOS PREDICTIVOS ======================
    elif analysis_type == "Modelos Predictivos":
        st.subheader("üîÆ Modelos Predictivos")
        
        # Pesta√±as para organizaci√≥n
        tab1, tab2, tab3 = st.tabs(["üèãÔ∏è Entrenar Modelo", "üîç Comparar Modelos", "üìä Comparar Todos"])
        
        with tab1:
            # [...] (todo el c√≥digo de entrenamiento anterior se mantiene igual)
            
            # MODIFICACI√ìN: Al final del entrenamiento, guardamos los resultados
            if st.button("Ejecutar Modelo"):
                # [...] (c√≥digo de entrenamiento anterior)
                
                # Guardamos resultados en session_state
                model_key = f"{model_choice}_{target_var}"
                st.session_state.model_results[model_key] = {
                    'model_type': model_type,
                    'metrics': {
                        'MSE': mse if model_type == "regression" else None,
                        'R2': r2 if model_type == "regression" else None,
                        'Accuracy': accuracy if model_type == "classification" else None,
                        'Precision': precision if model_type == "classification" else None,
                        'Recall': recall if model_type == "classification" else None,
                        'F1': f1 if model_type == "classification" else None
                    },
                    'model': model,
                    'predictors': predictor_vars,
                    'target': target_var,
                    'timestamp': pd.Timestamp.now()
                }
                
                st.success(f"Modelo {model_choice} guardado para comparaci√≥n!")
        
        with tab2:
            st.subheader("üîç Comparar Modelos Individuales")
            
            if not st.session_state.model_results:
                st.warning("No hay modelos entrenados para comparar")
            else:
                # Selecci√≥n de modelos a comparar
                available_models = list(st.session_state.model_results.keys())
                selected_models = st.multiselect(
                    "Selecciona modelos para comparar",
                    available_models,
                    default=available_models[:2]
                )
                
                if selected_models:
                    # Filtramos solo los modelos seleccionados
                    results_to_compare = {k: v for k, v in st.session_state.model_results.items() 
                                        if k in selected_models}
                    
                    # Creamos dataframe comparativo
                    comparison_data = []
                    for model_name, model_data in results_to_compare.items():
                        row = {'Modelo': model_name}
                        row.update(model_data['metrics'])
                        comparison_data.append(row)
                    
                    df_comparison = pd.DataFrame(comparison_data)
                    
                    # Mostramos tabla comparativa
                    st.write("### M√©tricas Comparativas")
                    st.dataframe(df_comparison.style.format("{:.4f}").highlight_max(axis=0))
                    
                    # Gr√°fico comparativo
                    st.write("### Visualizaci√≥n Comparativa")
                    
                    # Seleccionamos qu√© m√©tricas mostrar
                    if len(selected_models) > 0:
                        model_types = set(st.session_state.model_results[m]['model_type'] 
                                    for m in selected_models)
                        
                        if len(model_types) == 1:  # Todos son del mismo tipo
                            if "regression" in model_types:
                                metrics_to_show = ['MSE', 'R2']
                            else:
                                metrics_to_show = ['Accuracy', 'Precision', 'Recall', 'F1']
                            
                            fig, ax = plt.subplots(figsize=(10, 6))
                            df_comparison.set_index('Modelo')[metrics_to_show].plot(
                                kind='bar', ax=ax)
                            ax.set_title("Comparaci√≥n de Modelos")
                            ax.set_ylabel("Valor M√©trica")
                            st.pyplot(fig)
                        else:
                            st.warning("Los modelos seleccionados son de tipos diferentes (regresi√≥n/clasificaci√≥n)")

        with tab3:
            st.subheader("üìä Comparaci√≥n Autom√°tica de Todos los Modelos")
            
            if not st.session_state.model_results:
                st.warning("No hay modelos entrenados para comparar")
            else:
                # Separamos modelos por tipo
                regression_models = {k: v for k, v in st.session_state.model_results.items() 
                                   if v['model_type'] == 'regression'}
                classification_models = {k: v for k, v in st.session_state.model_results.items() 
                                       if v['model_type'] == 'classification'}
                
                # Comparaci√≥n de modelos de regresi√≥n
                if regression_models:
                    st.write("### üî¢ Modelos de Regresi√≥n")
                    reg_data = []
                    for model_name, model_data in regression_models.items():
                        row = {'Modelo': model_name}
                        row.update({k: v for k, v in model_data['metrics'].items() if v is not None})
                        reg_data.append(row)
                    
                    df_reg = pd.DataFrame(reg_data)
                    st.dataframe(df_reg.style.format("{:.4f}").highlight_max(axis=0))
                    
                    # Gr√°fico de regresi√≥n
                    if len(regression_models) > 1:
                        fig, ax = plt.subplots(figsize=(10, 4))
                        df_reg.set_index('Modelo').plot(kind='bar', ax=ax)
                        ax.set_title("Comparaci√≥n de Modelos de Regresi√≥n")
                        st.pyplot(fig)
                
                # Comparaci√≥n de modelos de clasificaci√≥n
                if classification_models:
                    st.write("### üè∑Ô∏è Modelos de Clasificaci√≥n")
                    clf_data = []
                    for model_name, model_data in classification_models.items():
                        row = {'Modelo': model_name}
                        row.update({k: v for k, v in model_data['metrics'].items() if v is not None})
                        clf_data.append(row)
                    
                    df_clf = pd.DataFrame(clf_data)
                    st.dataframe(df_clf.style.format("{:.4f}").highlight_max(axis=0))
                    
                    # Gr√°fico de clasificaci√≥n
                    if len(classification_models) > 1:
                        fig, ax = plt.subplots(figsize=(10, 6))
                        df_clf.set_index('Modelo').plot(kind='bar', ax=ax)
                        ax.set_title("Comparaci√≥n de Modelos de Clasificaci√≥n")
                        st.pyplot(fig)
                
                if not regression_models and not classification_models:
                    st.warning("No hay modelos para comparar")
